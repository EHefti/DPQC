{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b681791",
   "metadata": {},
   "source": [
    "## Import Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c5204-8fd1-4af1-8099-cdb44b14371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe926de3-d9ee-463f-9388-a9fffe288d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import spikeinterface.full as si\n",
    "import spikeinterface.curation as sc\n",
    "\n",
    "# Suppress warnings from spikeinterface\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add the path to the custom functions\n",
    "sys.path.append(\"/home/ehefti/Github/DPQC\")\n",
    "import _functions.spike_sorting as ss\n",
    "import _functions.screen_maxtwo_activity as sma\n",
    "import _functions.quality_control as qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897eb87",
   "metadata": {},
   "source": [
    "## 1. Recording Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1238d33-72ab-4452-a2a1-509e5853d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your paths\n",
    "# Linux: '/net/bs-filesvr02/export/group/hierlemann/recordings/Maxtwo/.../data.raw.h5' \n",
    "# Windows: 'S:/group/hierlemann02/recordings/Maxtwo/.../data.raw.h5'\n",
    "\n",
    "rec_path = '/net/bs-filesvr02/export/group/hierlemann/recordings/Maxtwo/phornauer/241218/EI_iNeurons/T002523/Network/000020/data.raw.h5'\n",
    "save_root = '/net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/phornauer/EI_iNeurons/241218/T002523/Network/'\n",
    "\n",
    "h5 = h5py.File(rec_path)\n",
    "stream_ids = list(h5['wells'].keys())\n",
    "stream_ids = stream_ids[0:24]\n",
    "\n",
    "\n",
    "df_summary, rate_dist, amp_dist = sma.screen_maxtwo_activity(rec_path, segment_duration_s=10,\n",
    "                                                             rate_lower_threshold = 0.5,\n",
    "                                                             rate_upper_threshold = 20,\n",
    "                                                             amp_lower_threshold = 30,\n",
    "                                                             amp_upper_threshold = 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f84ba9",
   "metadata": {},
   "source": [
    "## 2. Spikesorting\n",
    "_This part of the pipeline is computationally heavy. It is advisable to run this on a GPU or Cluster._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e006b-1a9f-4c5e-83b3-040f86f37f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose sorter and set parameters\n",
    "sorter = 'kilosort2_5'\n",
    "si.Kilosort2_5Sorter.set_kilosort2_5_path('/home/ehefti/Github/Kilosort')\n",
    "sorter_params = si.get_default_sorter_params(si.Kilosort2_5Sorter)\n",
    "\n",
    "sorter_params['n_jobs'] = -1\n",
    "sorter_params['detect_threshold'] = 5.5 #6 als Standardwert\n",
    "sorter_params['minFR'] = 0.01 #Lower value -> less units that get automatically deleted\n",
    "sorter_params['minfr_goodchannels'] = 0.01\n",
    "sorter_params['keep_good_only'] = False\n",
    "sorter_params['do_correction'] = False\n",
    "sorter_params['NT'] = 64*1024 + 64 #Batch size -> Wieviel wird auf einmal angeschaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a9743-8a70-4b77-86b2-4dbdc48c01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream_id in tqdm(stream_ids):\n",
    "    h5 = h5py.File(rec_path)\n",
    "    rec_name = list(h5['wells'][stream_id].keys())[0]\n",
    "    rec = si.MaxwellRecordingExtractor(rec_path, stream_id=stream_id, rec_name=rec_name)\n",
    "    ss.clean_sorting(rec, save_root, stream_id=stream_id, sorter=sorter, sorter_params=sorter_params, clear_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3d9c7",
   "metadata": {},
   "source": [
    "## 3. Qualitycontrol (Machine Learning Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51a643",
   "metadata": {},
   "source": [
    "You can train your own Model if you want - this is not necessary though. There is a model that works reasonably well for MaxTwo EPhys data. If you train your own model it might be more precise for your cell-line, but it takes a while to label your units manually and train the model to get reasonable results. The pretrained Model will be loaded in the next step of the pipeline, you can jump to \"Apply Model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade41bc5",
   "metadata": {},
   "source": [
    "### Training your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a01b7f7-4c4b-4561-9997-4a4589d2e730",
   "metadata": {},
   "source": [
    "```python\n",
    "# If you want to testrun the code you can use this function and skip the next code block:\n",
    "rec_train, sorting_train, analyzer = generate_ground_truth_data(\n",
    "    durations=[10], \n",
    "    sampling_frequency=30000,\n",
    "    num_channels=4\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b20b1f",
   "metadata": {},
   "source": [
    "Creating an analyzer for your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2f45e-9309-4163-a7ef-4e0387f76e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! This controls how many cores you're using, only increase if the server is not used by others !!\n",
    "si.set_global_job_kwargs(n_jobs = 6) # For no parallelisation use n_jobs = -1\n",
    "os.environ['HDF5_PLUGIN_PATH'] = '/home/ehefti/Github/DPQC/MaxTwo_Quality_Control/'\n",
    "\n",
    "#Choose the well you want to use for training the model\n",
    "well_id = 'well001'\n",
    "\n",
    "rec_train, sorting_train, analyzer = qc.compute_analyzer(rec_path, save_root, well_id, num_units_to_use='all', hp_cutoff_freq=300)\n",
    "\n",
    "# Plot some unit templates\n",
    "all_unit_ids = sorting_train.get_unit_ids()\n",
    "si.plot_unit_templates(analyzer, unit_ids=all_unit_ids[:3], scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d474f",
   "metadata": {},
   "source": [
    "Manually labeling the units in the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b646de6-a3d4-442d-883f-1938a52fdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the directory where you want to save the labels\n",
    "label_output_dir = Path(save_root) / well_id / 'sorter_output'\n",
    "\n",
    "# Interactive GUI to manually label your data\n",
    "updated_sorting = qc.interactive_unit_labeler(rec_train, sorting_train, analyzer, output_dir_for_labels=label_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20587b8",
   "metadata": {},
   "source": [
    "Training your model, given the manual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6823f0d-2ec1-4855-9ece-b8070926ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the folder where your model should be saved\n",
    "model_folder = \"_models/\"\n",
    "\n",
    "# Load the labels from the chosed directory above\n",
    "manual_labels = pd.read_csv(label_output_dir, sep='\\t')\n",
    "manual_labels = manual_labels['quality_label'].tolist()\n",
    "\n",
    "manual_labels = ['good' if unit_type == 'good' else 'bad' for unit_type in manual_labels]\n",
    "\n",
    "# Train the model\n",
    "trainer = sc.train_model(\n",
    "    mode=\"analyzers\",\n",
    "    labels=[manual_labels],\n",
    "    analyzers=[analyzer],\n",
    "    folder=model_folder,\n",
    "    overwrite=True, # Set to True if you want to overwrite existing models\n",
    "    imputation_strategies = [\"median\"],\n",
    "    scaling_techniques = [\"standard_scaler\"],\n",
    "    classifiers = None, # Default: Random Forest. Other Classifiers: [ \"AdaBoostClassifier\",\"GradientBoostingClassifier\",\"LogisticRegression\",\"MLPClassifier\"]\n",
    "    search_kwargs = {'scoring': 'balanced_accuracy', 'cv': 3} # Parameters used during the model hyperparameter search\n",
    ")\n",
    "\n",
    "best_model = trainer.best_pipeline\n",
    "\n",
    "accuracies = pd.read_csv(Path(model_folder) / \"model_accuracies.csv\", index_col = 0)\n",
    "accuracies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c2088",
   "metadata": {},
   "source": [
    "Evaluate your model's confidence and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652644c4-5a22-4a3f-9863-d34d15dab8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the model confidence and accuracy while plotting a confusion matrix\n",
    "qc.plot_model_evaluation(analyzer=analyzer, model_folder=model_folder, manual_labels=manual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc45506",
   "metadata": {},
   "source": [
    "### Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8193099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model if you did not train you own\n",
    "if 'model_folder' not in locals():\n",
    "    model_folder = '_models/'\n",
    "\n",
    "\n",
    "# Run the model for all wells except the one you used for training\n",
    "left_stream_ids = [stream_id for stream_id in stream_ids if stream_id != well_id]\n",
    "for stream_id in tqdm(left_stream_ids):\n",
    "    qc.auto_label_stream(rec_path, save_root, stream_id, model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpqc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
