{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b681791",
   "metadata": {},
   "source": [
    "## Import Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c5204-8fd1-4af1-8099-cdb44b14371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe926de3-d9ee-463f-9388-a9fffe288d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from pathlib import Path\n",
    "from statistics import mean\n",
    "from glob import glob\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import sklearn\n",
    "import h5py\n",
    "import spikeinterface.full as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.curation as sc\n",
    "import spikeinterface.widgets as sw\n",
    "\n",
    "\n",
    "\n",
    "import bombcell as bc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "sys.path.append(\"/home/ehefti/Github/DPQC\")\n",
    "# sys.path.append(\"C:/Users/elias/OneDrive - ETH Zurich/2025FS - Master Thesis/1 - Scripts/Github/DPQC\")\n",
    "import MaxTwo_Spikesorting.scripts.spike_sorting as ss\n",
    "import MaxTwo_Activity_Screening.screen_maxtwo_activity as sma\n",
    "import KiloSort_Quality_Control.unit_labeling as ul\n",
    "import KiloSort_Quality_Control.model_evaluation as me\n",
    "import KiloSort_Quality_Control.compute_analyzer as ca\n",
    "import KiloSort_Quality_Control.label_stream as ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e897eb87",
   "metadata": {},
   "source": [
    "## 1. Recording Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1238d33-72ab-4452-a2a1-509e5853d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_path = '/net/bs-filesvr02/export/group/hierlemann/recordings/Maxtwo/phornauer/241218/EI_iNeurons/T002523/Network/000020/data.raw.h5'\n",
    "df_summary, rate_dist, amp_dist = sma.screen_maxtwo_activity(rec_path, segment_duration_s=10,\n",
    "                                                             rate_lower_threshold = 0.5,\n",
    "                                                             rate_upper_threshold = 20,\n",
    "                                                             amp_lower_threshold = 30,\n",
    "                                                             amp_upper_threshold = 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f84ba9",
   "metadata": {},
   "source": [
    "## 2. Spikesorting\n",
    "_This part of the pipeline is computationally heavy. It is advisable to run this on a GPU or Cluster._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e006b-1a9f-4c5e-83b3-040f86f37f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your paths\n",
    "# Linux: '/net/bs-filesvr02/export/group/hierlemann/recordings/Maxtwo/.../data.raw.h5' \n",
    "# Windows: 'S:/group/hierlemann02/recordings/Maxtwo/.../data.raw.h5'\n",
    "\n",
    "rec_path = '/net/bs-filesvr02/export/group/hierlemann/recordings/Maxtwo/phornauer/241218/EI_iNeurons/T002523/Network/000020/data.raw.h5'\n",
    "save_root = '/net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/phornauer/EI_iNeurons/241218/T002523/Network/'\n",
    "\n",
    "h5 = h5py.File(rec_path)\n",
    "stream_ids = list(h5['wells'].keys())\n",
    "stream_ids = stream_ids[0:24]\n",
    "\n",
    "# ---------------------------------- #\n",
    "\n",
    "# Choose sorter and set parameters\n",
    "sorter = 'kilosort2_5'\n",
    "si.Kilosort2_5Sorter.set_kilosort2_5_path('/home/ehefti/Github/Kilosort')\n",
    "sorter_params = si.get_default_sorter_params(si.Kilosort2_5Sorter)\n",
    "\n",
    "sorter_params['n_jobs'] = -1\n",
    "sorter_params['detect_threshold'] = 5.5 #6 als Standardwert\n",
    "sorter_params['minFR'] = 0.01 #Lower value -> less units that get automatically deleted\n",
    "sorter_params['minfr_goodchannels'] = 0.01\n",
    "sorter_params['keep_good_only'] = False\n",
    "sorter_params['do_correction'] = False\n",
    "sorter_params['NT'] = 64*1024 + 64 #Batch size -> Wieviel wird auf einmal angeschaut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a9743-8a70-4b77-86b2-4dbdc48c01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream_id in tqdm(stream_ids):\n",
    "    h5 = h5py.File(rec_path)\n",
    "    rec_name = list(h5['wells'][stream_id].keys())[0]\n",
    "    rec = si.MaxwellRecordingExtractor(rec_path, stream_id=stream_id, rec_name=rec_name)\n",
    "    ss.clean_sorting(rec, save_root, stream_id=stream_id, sorter=sorter, sorter_params=sorter_params, clear_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3d9c7",
   "metadata": {},
   "source": [
    "## 3. Qualitycontrol (Machine Learning Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca51a643",
   "metadata": {},
   "source": [
    "You can train your own Model if you want - this is not necessary though. There is a model that works reasonably well for MaxTwo EPhys data. If you train your own model it might be more precise for your cell-line, but it takes a while to label your units manually and train the model to get reasonable results. The pretrained Model will be loaded in the next step of the pipeline, you can jump to \"Apply Model\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e4df7",
   "metadata": {},
   "source": [
    "##### Manual Labeling [Side Note]\n",
    "Alternatively you can also download phy by following the instructions on the following GitHub repository: `https://github.com/cortex-lab/phy/`. Phy offers a GUI with more information about the units, but you will have to leave jupyter notebook and create a dedicated conda environment for it.\n",
    "\n",
    "The documentation to explain the GUI can be found here `https://phy.readthedocs.io/en/latest/`\n",
    "\n",
    "You can also start the GUI from python, but you will have to change the kernel which makes you loose your cached variables. Use the code below:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "from phy.apps.template import template_gui\n",
    "from pathlib import Path\n",
    "\n",
    "save_root = 'your/path/to/your/sorted/wells/'\n",
    "well_id = 'well010'\n",
    "params_path = Path(save_root) / well_id / 'sorter_output' / 'params.py'\n",
    "template_gui(params_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade41bc5",
   "metadata": {},
   "source": [
    "### Training your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01b7f7-4c4b-4561-9997-4a4589d2e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# If you want to testrun the code you can use this function and skip the next code block:\n",
    "rec_train, sorting_train, analyzer = generate_ground_truth_data(\n",
    "    durations=[10], \n",
    "    sampling_frequency=30000, \n",
    "    num_channels=4\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b20b1f",
   "metadata": {},
   "source": [
    "Creating an analyzer for your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2f45e-9309-4163-a7ef-4e0387f76e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! This controls how many cores you're using, only increase if the server is not used by others !!\n",
    "si.set_global_job_kwargs(n_jobs = 6) # For no parallelisation use n_jobs = -1\n",
    "os.environ['HDF5_PLUGIN_PATH'] = '/home/ehefti/Github/DPQC/MaxTwo_Quality_Control/'\n",
    "\n",
    "#Choose the well you want to use for training the model\n",
    "well_id = 'well001'\n",
    "\n",
    "rec_train, sorting_train, analyzer = ca.compute_analyzer(rec_path, save_root, well_id, num_units_to_use='all', hp_cutoff_freq=300)\n",
    "\n",
    "# Plot some unit templates\n",
    "all_unit_ids = sorting_train.get_unit_ids()\n",
    "si.plot_unit_templates(analyzer, unit_ids=all_unit_ids[:3], scale=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d474f",
   "metadata": {},
   "source": [
    "Manually labeling the units in the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd7bbc-ea8f-463b-9b87-df4cd8c71689",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# If you used Bombcell and want to use its labels for the training of the model, load the with the following code:\n",
    "df = pd.read_csv(path_to_sorting / 'cluster_KSLabel.tsv', sep='\\t')\n",
    "manual_labels = ['good' if unit_type == 'GOOD' else 'bad' for unit_type in df['bc_unitType']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b646de6-a3d4-442d-883f-1938a52fdaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the directory where you want to save the labels\n",
    "label_output_dir = Path(save_root) / well_id / 'sorter_output'\n",
    "\n",
    "# Interactive GUI to manually label your data\n",
    "updated_sorting = ul.interactive_unit_labeler(rec_train, sorting_train, analyzer, output_dir_for_labels=label_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20587b8",
   "metadata": {},
   "source": [
    "Training your model, given the manual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6823f0d-2ec1-4855-9ece-b8070926ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the folder where your model should be saved\n",
    "model_folder = \"models/\"\n",
    "\n",
    "# Load the labels from the chosed directory above\n",
    "manual_labels = pd.read_csv(label_output_dir, sep='\\t')\n",
    "manual_labels = manual_labels['quality_label'].tolist()\n",
    "\n",
    "manual_labels = ['good' if unit_type == 'good' else 'bad' for unit_type in manual_labels]\n",
    "\n",
    "# Train the model\n",
    "trainer = sc.train_model(\n",
    "    mode=\"analyzers\",\n",
    "    labels=[manual_labels],\n",
    "    analyzers=[analyzer],\n",
    "    folder=model_folder,\n",
    "    overwrite=True,                             # Set to True if you want to overwrite existing models\n",
    "    imputation_strategies = [\"median\"],\n",
    "    scaling_techniques = [\"standard_scaler\"],\n",
    "    classifiers = None,                         # Default: Random Forest. Other classifiers you can try [ \"AdaBoostClassifier\",\"GradientBoostingClassifier\",\"LogisticRegression\",\"MLPClassifier\"]\n",
    "    search_kwargs = {'scoring': 'balanced_accuracy', 'cv': 3} # Parameters used during the model hyperparameter search\n",
    ")\n",
    "\n",
    "best_model = trainer.best_pipeline\n",
    "\n",
    "accuracies = pd.read_csv(Path(model_folder) / \"model_accuracies.csv\", index_col = 0)\n",
    "accuracies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c2088",
   "metadata": {},
   "source": [
    "Evaluate your model's confidence and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652644c4-5a22-4a3f-9863-d34d15dab8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the model confidence and accuracy while plotting a confusion matrix\n",
    "me.plot_model_evaluation(analyzer=analyzer, model_folder=model_folder, manual_labels=manual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc45506",
   "metadata": {},
   "source": [
    "### Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8193099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model if you did not train you own\n",
    "if 'model_folder' not in locals():\n",
    "    model_folder = 'models/'\n",
    "\n",
    "\n",
    "# Run the model for all wells except the one you used for training\n",
    "left_stream_ids = [stream_id for stream_id in stream_ids if stream_id != well_id]\n",
    "for stream_id in tqdm(left_stream_ids):\n",
    "    ls.auto_label_stream(rec_path, save_root, stream_id, model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpqc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
