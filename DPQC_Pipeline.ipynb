{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b681791",
   "metadata": {},
   "source": [
    "## Packages and Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1c5204-8fd1-4af1-8099-cdb44b14371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe926de3-d9ee-463f-9388-a9fffe288d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import spikeinterface.full as si\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matlab.engine\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(\"C:/Users/elias/OneDrive - ETH Zurich/2025FS - Master Thesis/1 - Scripts/Github/DPQC\")\n",
    "import MaxTwo_Spikesorting.scripts.spike_sorting as ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a956fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = '/net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/lkaupp/Dup15q/250429/T002513/ActivityScan/000007/data.raw.h5'\n",
    "outputDir = '/net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/ehefti/Dup15q/Figures'\n",
    "\n",
    "os.makedirs(outputDir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8e006b-1a9f-4c5e-83b3-040f86f37f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting KILOSORT2_5_PATH environment variable for subprocess calls to: c:\\home\\ehefti\\Github\\Kilosort\n"
     ]
    }
   ],
   "source": [
    "sorter = 'kilosort2_5'\n",
    "si.Kilosort2_5Sorter.set_kilosort2_5_path('/home/ehefti/Github/Kilosort')\n",
    "sorter_params = si.get_default_sorter_params(si.Kilosort2_5Sorter)\n",
    "# print(sorter_params)\n",
    "sorter_params['n_jobs'] = -1\n",
    "sorter_params['detect_threshold'] = 5.5 #6 als Standardwert\n",
    "# sorter_params['preclust_threshold'] = 5\n",
    "# sorter_params['projection_threshold'] = [8, 4]\n",
    "# sorter_params['AUCsplit'] = 0.8\n",
    "sorter_params['minFR'] = 0.01 #Lower value -> less units that get automatically deleted\n",
    "sorter_params['minfr_goodchannels'] = 0.01\n",
    "sorter_params['keep_good_only'] = False\n",
    "sorter_params['do_correction'] = False\n",
    "sorter_params['NT'] = 64*1024 + 64 #Batch size -> Wieviel wird auf einmal angeschaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437a9743-8a70-4b77-86b2-4dbdc48c01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/net/bs-filesvr02/export/group/hierlemann/recordings/Maxtwo/phornauer/241009/Torsten_2/T002523/Network/000002/data.raw.h5' \n",
    "# S:\\group\\hierlemann02\\intermediate_data\\Maxtwo\\cmartins\\Recordings\\ST2036\\ST2036E\\240705\\T002736\\Network\n",
    "\n",
    "path = 'S:/group/hierlemann02/recordings/Maxtwo/phornauer/241218/EI_iNeurons/T002523/Network/000020/data.raw.h5'\n",
    "h5 = h5py.File(path)\n",
    "stream_ids = list(h5['wells'].keys())\n",
    "stream_ids = stream_ids[1:24]\n",
    "\n",
    "save_root = 'D:/Master Thesis/Data/EI_iNeurons/241218/T002523/Network'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfe22f",
   "metadata": {},
   "source": [
    "## Spikesorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b2d1c-00f2-4cb3-89b0-58b041622622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                        | 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 1800.02 s -- NUM. CHANNELS: 1002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f267c8264ed241af8c29fd535c965611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 8 processes):   0%|          | 0/1801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/ehefti/Dup15q/250429/T003104/Network/well001/sorter_output/run_kilosort2_5.sh\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2024 The MathWorks, Inc.\n",
      "\n",
      "                  R2024b (24.2.0.2712019) 64-bit (glnxa64)\n",
      "\n",
      "                              August 22, 2024\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      " \n",
      "\n",
      "Time   0s. Computing whitening matrix.. \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Time  26s. Loading raw data and applying filters... \n",
      "\n",
      "Time 814s. Finished preprocessing 275 batches. \n",
      "\n",
      "Drift correction DISABLED\n",
      "\n",
      "pitch is 1.750000e+01 um\n",
      "\n",
      "0.79 sec, 1 batches, 2273 spikes \n",
      "\n",
      "171.66 sec, 101 batches, 227940 spikes \n",
      "\n",
      "341.57 sec, 201 batches, 454118 spikes \n",
      "\n",
      "468.62 sec, 275 batches, 620501 spikes \n",
      "\n",
      "time 472.99, Skipped shifting 275 batches. \n",
      "\n",
      "Time 476s. Optimizing templates ...\n",
      "\n",
      "476.80 sec, 1 / 275 batches, 121 units, nspks: 17.8408, mu: 10.0000, nst0: 202, merges: 0.0000, 0.0000, 6.1000 \n",
      "\n",
      "507.18 sec, 101 / 275 batches, 251 units, nspks: 1327.8081, mu: 16.2121, nst0: 1342, merges: 277.4564, 0.5487, 61.2125 \n",
      "\n",
      "536.21 sec, 201 / 275 batches, 256 units, nspks: 1401.2370, mu: 15.4747, nst0: 1368, merges: 291.0061, 0.1199, 58.8526 \n",
      "\n",
      "Elapsed time is 557.781418 seconds.\n",
      "\n",
      "Finished learning templates \n",
      "\n",
      "Time 558s. Optimizing templates ...\n",
      "\n",
      "558.36 sec, 1 / 275 batches, 186 units, nspks: 1395.0000, mu: 16.6436, nst0: 2197 \n",
      "\n",
      "576.02 sec, 101 / 275 batches, 186 units, nspks: 145003.0000, mu: 16.6436, nst0: 2268 \n",
      "\n",
      "593.64 sec, 201 / 275 batches, 186 units, nspks: 288862.0000, mu: 16.6436, nst0: 2182 \n",
      "\n",
      "Elapsed time is 606.652041 seconds.\n",
      "\n",
      "Number of spikes before applying cutoff: 607309\n",
      "\n",
      "initialized spike counts\n",
      "\n",
      "merged 60 into 183 \n",
      "\n",
      "merged 79 into 77 \n",
      "\n",
      "merged 14 into 13 \n",
      "\n",
      "merged 15 into 13 \n",
      "\n",
      "merged 47 into 13 \n",
      "\n",
      "merged 125 into 124 \n",
      "\n",
      "merged 69 into 48 \n",
      "\n",
      "merged 30 into 34 \n",
      "\n",
      "merged 176 into 175 \n",
      "\n",
      "merged 49 into 48 \n",
      "\n",
      "merged 181 into 182 \n",
      "\n",
      "merged 29 into 34 \n",
      "\n",
      "merged 97 into 98 \n",
      "\n",
      "merged 37 into 38 \n",
      "\n",
      "merged 42 into 41 \n",
      "\n",
      "merged 88 into 7 \n",
      "\n",
      "Found 0 splits, checked 1/186 clusters, nccg 1 \n",
      "\n",
      "Found 8 splits, checked 101/194 clusters, nccg 67 \n",
      "\n",
      "Finished splitting. Found 11 splits, checked 197/197 clusters, nccg 141 \n",
      "\n",
      "Removing 106445 spikes below cutoff from rez.\n",
      "\n",
      "found 155 good units \n",
      "\n",
      "Saving results to Phy  \n",
      "\n",
      "kilosort2_5 run time 1501.24s\n",
      "\n",
      "\n",
      "Spike sorting elapsed time 2398.096793651581 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█████▎                                                                                                                     | 1/23 [40:03<14:41:21, 2403.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 1800.02 s -- NUM. CHANNELS: 995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bbcc2be801403fbe301acfa6f133d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 8 processes):   0%|          | 0/1801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/ehefti/Dup15q/250429/T003104/Network/well002/sorter_output/run_kilosort2_5.sh\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2024 The MathWorks, Inc.\n",
      "\n",
      "                  R2024b (24.2.0.2712019) 64-bit (glnxa64)\n",
      "\n",
      "                              August 22, 2024\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      " \n",
      "\n",
      "Time   0s. Computing whitening matrix.. \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Time  28s. Loading raw data and applying filters... \n",
      "\n",
      "Time 796s. Finished preprocessing 275 batches. \n",
      "\n",
      "Drift correction DISABLED\n",
      "\n",
      "pitch is 1.750000e+01 um\n",
      "\n",
      "0.74 sec, 1 batches, 1909 spikes \n",
      "\n",
      "169.65 sec, 101 batches, 184726 spikes \n",
      "\n",
      "338.81 sec, 201 batches, 364489 spikes \n",
      "\n",
      "465.61 sec, 275 batches, 496303 spikes \n",
      "\n",
      "time 470.15, Skipped shifting 275 batches. \n",
      "\n",
      "Time 473s. Optimizing templates ...\n",
      "\n",
      "475.14 sec, 1 / 275 batches, 153 units, nspks: 27.8744, mu: 18.9005, nst0: 362, merges: 0.0000, 0.0000, 7.3000 \n",
      "\n",
      "504.69 sec, 101 / 275 batches, 214 units, nspks: 1141.0433, mu: 16.0401, nst0: 1243, merges: 248.2608, 0.2547, 52.4916 \n",
      "\n",
      "532.92 sec, 201 / 275 batches, 181 units, nspks: 1220.3840, mu: 15.4867, nst0: 1164, merges: 249.7124, 0.0310, 47.6651 \n",
      "\n",
      "Elapsed time is 553.599173 seconds.\n",
      "\n",
      "Finished learning templates \n",
      "\n",
      "Time 554s. Optimizing templates ...\n",
      "\n",
      "554.18 sec, 1 / 275 batches, 152 units, nspks: 1211.0000, mu: 16.8453, nst0: 1533 \n",
      "\n",
      "570.79 sec, 101 / 275 batches, 152 units, nspks: 123604.0000, mu: 16.8453, nst0: 1613 \n",
      "\n",
      "587.20 sec, 201 / 275 batches, 152 units, nspks: 244863.0000, mu: 16.8453, nst0: 1504 \n",
      "\n",
      "Elapsed time is 599.364572 seconds.\n",
      "\n",
      "Number of spikes before applying cutoff: 419312\n",
      "\n",
      "initialized spike counts\n",
      "\n",
      "merged 92 into 91 \n",
      "\n",
      "merged 97 into 99 \n",
      "\n",
      "merged 111 into 113 \n",
      "\n",
      "merged 3 into 2 \n",
      "\n",
      "merged 98 into 104 \n",
      "\n",
      "merged 100 into 104 \n",
      "\n",
      "merged 122 into 121 \n",
      "\n",
      "merged 79 into 80 \n",
      "\n",
      "merged 99 into 104 \n",
      "\n",
      "merged 27 into 28 \n",
      "\n",
      "merged 12 into 13 \n",
      "\n",
      "merged 105 into 102 \n",
      "\n",
      "Found 0 splits, checked 1/152 clusters, nccg 0 \n",
      "\n",
      "Found 7 splits, checked 101/159 clusters, nccg 69 \n",
      "\n",
      "Finished splitting. Found 10 splits, checked 162/162 clusters, nccg 102 \n",
      "\n",
      "Removing 28059 spikes below cutoff from rez.\n",
      "\n",
      "found 121 good units \n",
      "\n",
      "Saving results to Phy  \n",
      "\n",
      "kilosort2_5 run time 1480.62s\n",
      "\n",
      "\n",
      "Spike sorting elapsed time 2122.0724725723267 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████▌                                                                                                              | 2/23 [1:15:31<13:04:33, 2241.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 1800.02 s -- NUM. CHANNELS: 999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c996a19473cb458c854b5e1f7234f8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 8 processes):   0%|          | 0/1801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/ehefti/Dup15q/250429/T003104/Network/well003/sorter_output/run_kilosort2_5.sh\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2024 The MathWorks, Inc.\n",
      "\n",
      "                  R2024b (24.2.0.2712019) 64-bit (glnxa64)\n",
      "\n",
      "                              August 22, 2024\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      " \n",
      "\n",
      "Time   0s. Computing whitening matrix.. \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Time  28s. Loading raw data and applying filters... \n",
      "\n",
      "Time 806s. Finished preprocessing 275 batches. \n",
      "\n",
      "Drift correction DISABLED\n",
      "\n",
      "pitch is 1.750000e+01 um\n",
      "\n",
      "0.75 sec, 1 batches, 2492 spikes \n",
      "\n",
      "171.21 sec, 101 batches, 249316 spikes \n",
      "\n",
      "341.70 sec, 201 batches, 493182 spikes \n",
      "\n",
      "468.64 sec, 275 batches, 670636 spikes \n",
      "\n",
      "time 473.07, Skipped shifting 275 batches. \n",
      "\n",
      "Time 477s. Optimizing templates ...\n",
      "\n",
      "477.27 sec, 1 / 275 batches, 164 units, nspks: 40.2927, mu: 10.0000, nst0: 596, merges: 0.0000, 0.0000, 8.3000 \n",
      "\n",
      "508.46 sec, 101 / 275 batches, 256 units, nspks: 1537.2079, mu: 15.9795, nst0: 1598, merges: 288.9533, 0.4163, 63.7019 \n",
      "\n",
      "538.17 sec, 201 / 275 batches, 240 units, nspks: 1591.7954, mu: 14.8482, nst0: 1577, merges: 295.2364, 0.0823, 58.6240 \n",
      "\n",
      "Elapsed time is 559.904736 seconds.\n",
      "\n",
      "Finished learning templates \n",
      "\n",
      "Time 560s. Optimizing templates ...\n",
      "\n",
      "560.48 sec, 1 / 275 batches, 167 units, nspks: 1589.0000, mu: 16.1829, nst0: 2031 \n",
      "\n",
      "578.08 sec, 101 / 275 batches, 167 units, nspks: 165236.0000, mu: 16.1829, nst0: 2127 \n",
      "\n",
      "595.56 sec, 201 / 275 batches, 167 units, nspks: 328112.0000, mu: 16.1829, nst0: 2054 \n",
      "\n",
      "Elapsed time is 608.542354 seconds.\n",
      "\n",
      "Number of spikes before applying cutoff: 570982\n",
      "\n",
      "initialized spike counts\n",
      "\n",
      "merged 122 into 120 \n",
      "\n",
      "merged 80 into 79 \n",
      "\n",
      "merged 123 into 120 \n",
      "\n",
      "merged 166 into 165 \n",
      "\n",
      "merged 121 into 120 \n",
      "\n",
      "merged 7 into 8 \n",
      "\n",
      "merged 6 into 8 \n",
      "\n",
      "merged 93 into 75 \n",
      "\n",
      "merged 9 into 8 \n",
      "\n",
      "Found 0 splits, checked 1/167 clusters, nccg 1 \n",
      "\n",
      "Found 1 splits, checked 1/168 clusters, nccg 1 \n",
      "\n",
      "Found 9 splits, checked 101/176 clusters, nccg 71 \n",
      "\n",
      "Finished splitting. Found 17 splits, checked 184/184 clusters, nccg 126 \n",
      "\n",
      "Removing 68528 spikes below cutoff from rez.\n",
      "\n",
      "found 144 good units \n",
      "\n",
      "Saving results to Phy  \n",
      "\n",
      "kilosort2_5 run time 1486.22s\n",
      "\n",
      "\n",
      "Spike sorting elapsed time 2155.4848709106445 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|███████████████▊                                                                                                         | 3/23 [1:51:33<12:15:03, 2205.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 1800.02 s -- NUM. CHANNELS: 1008\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0dc3944f6343599d820c112e584269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 8 processes):   0%|          | 0/1801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SHELL SCRIPT: /net/bs-filesvr02/export/group/hierlemann/intermediate_data/Maxtwo/ehefti/Dup15q/250429/T003104/Network/well004/sorter_output/run_kilosort2_5.sh\n",
      "\n",
      "\n",
      "                            < M A T L A B (R) >\n",
      "\n",
      "                  Copyright 1984-2024 The MathWorks, Inc.\n",
      "\n",
      "                  R2024b (24.2.0.2712019) 64-bit (glnxa64)\n",
      "\n",
      "                              August 22, 2024\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "To get started, type doc.\n",
      "\n",
      "For product information, visit www.mathworks.com.\n",
      "\n",
      " \n",
      "\n",
      "Time   0s. Computing whitening matrix.. \n",
      "\n",
      "Getting channel whitening matrix... \n",
      "\n",
      "Channel-whitening matrix computed. \n",
      "\n",
      "Time  26s. Loading raw data and applying filters... \n",
      "\n",
      "Time 766s. Finished preprocessing 275 batches. \n",
      "\n",
      "Drift correction DISABLED\n",
      "\n",
      "pitch is 1.750000e+01 um\n",
      "\n",
      "0.75 sec, 1 batches, 2370 spikes \n",
      "\n",
      "171.50 sec, 101 batches, 232683 spikes \n",
      "\n",
      "341.30 sec, 201 batches, 461219 spikes \n",
      "\n",
      "469.30 sec, 275 batches, 629739 spikes \n",
      "\n",
      "time 473.19, Skipped shifting 275 batches. \n",
      "\n",
      "Time 477s. Optimizing templates ...\n",
      "\n",
      "477.44 sec, 1 / 275 batches, 180 units, nspks: 38.5562, mu: 19.8582, nst0: 541, merges: 0.0000, 0.0000, 8.8000 \n",
      "\n",
      "506.55 sec, 101 / 275 batches, 224 units, nspks: 1363.3925, mu: 14.9542, nst0: 1371, merges: 293.1923, 0.3184, 64.4201 \n",
      "\n",
      "534.26 sec, 201 / 275 batches, 232 units, nspks: 1415.6684, mu: 14.8855, nst0: 1381, merges: 313.7275, 0.0818, 63.3744 \n",
      "\n",
      "Elapsed time is 554.633353 seconds.\n",
      "\n",
      "Finished learning templates \n",
      "\n",
      "Time 555s. Optimizing templates ...\n",
      "\n",
      "555.20 sec, 1 / 275 batches, 165 units, nspks: 1396.0000, mu: 17.0688, nst0: 1640 \n",
      "\n",
      "570.81 sec, 101 / 275 batches, 165 units, nspks: 143341.0000, mu: 17.0688, nst0: 1614 \n",
      "\n",
      "586.48 sec, 201 / 275 batches, 165 units, nspks: 285182.0000, mu: 17.0688, nst0: 1682 \n",
      "\n",
      "Elapsed time is 598.119039 seconds.\n",
      "\n",
      "Number of spikes before applying cutoff: 461022\n",
      "\n",
      "initialized spike counts\n",
      "\n",
      "merged 10 into 126 \n",
      "\n",
      "merged 165 into 164 \n",
      "\n",
      "merged 49 into 50 \n",
      "\n",
      "merged 116 into 115 \n",
      "\n",
      "merged 25 into 24 \n",
      "\n",
      "Found 0 splits, checked 1/165 clusters, nccg 1 \n",
      "\n",
      "Found 4 splits, checked 101/169 clusters, nccg 62 \n",
      "\n",
      "Finished splitting. Found 8 splits, checked 173/173 clusters, nccg 108 \n",
      "\n",
      "Removing 35718 spikes below cutoff from rez.\n",
      "\n",
      "found 139 good units \n",
      "\n",
      "Saving results to Phy  \n",
      "\n",
      "kilosort2_5 run time 1426.89s\n",
      "\n",
      "\n",
      "Spike sorting elapsed time 2100.6043643951416 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████████████████████                                                                                                    | 4/23 [2:26:40<11:26:02, 2166.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION: 1800.02 s -- NUM. CHANNELS: 998\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4afb3a9c5942d2b7b5c02899b740ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 8 processes):   0%|          | 0/1801 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for stream_id in tqdm(stream_ids):\n",
    "    h5 = h5py.File(path)\n",
    "    rec_name = list(h5['wells'][stream_id].keys())[0]\n",
    "    rec = si.MaxwellRecordingExtractor(path, stream_id=stream_id, rec_name=rec_name)\n",
    "    ss.clean_sorting(rec, save_root, stream_id=stream_id, sorter=sorter, sorter_params=sorter_params, clear_files=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3d9c7",
   "metadata": {},
   "source": [
    "## Qualitycontrol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec57870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimate_sparsity (no parallelization):   0%|          | 0/1801 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Maxwell file format is based on HDF5.\n",
      "The internal compression requires a custom plugin!!!\n",
      "This is a big pain for the end user.\n",
      "You, as a end user, should ask Maxwell company to change this.\n",
      "Please visit this page and install the missing decompression libraries:\n",
      "https://share.mxwbio.com/d/4742248b2e674a85be97/\n",
      "Then, link the decompression library by setting the `HDF5_PLUGIN_PATH` to your\n",
      "installation location, e.g. via\n",
      "os.environ['HDF5_PLUGIN_PATH'] = '/path/to/custom/hdf5/plugin/'\n",
      "\n",
      "Alternatively, you can use the auto_install_maxwell_hdf5_compression_plugin() below\n",
      "function that do it automagically.\n",
      "\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't synchronously read data (can't open directory)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m rec_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(h5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwells\u001b[39m\u001b[38;5;124m'\u001b[39m][well_id]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m rec_train \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mMaxwellRecordingExtractor(path, stream_id\u001b[38;5;241m=\u001b[39mwell_id, rec_name\u001b[38;5;241m=\u001b[39mrec_name)\n\u001b[1;32m---> 13\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m \u001b[43msi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_sorting_analyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorting_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecording\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrec_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\core\\sortinganalyzer.py:152\u001b[0m, in \u001b[0;36mcreate_sorting_analyzer\u001b[1;34m(sorting, recording, format, folder, sparse, sparsity, return_scaled, overwrite, backend_options, **sparsity_kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(\n\u001b[0;32m    149\u001b[0m         recording\u001b[38;5;241m.\u001b[39mchannel_ids, sparsity\u001b[38;5;241m.\u001b[39mchannel_ids\n\u001b[0;32m    150\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_sorting_analyzer(): if external sparsity is given unit_ids must correspond\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sparse:\n\u001b[1;32m--> 152\u001b[0m     sparsity \u001b[38;5;241m=\u001b[39m estimate_sparsity(sorting, recording, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msparsity_kwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     sparsity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\core\\sparsity.py:820\u001b[0m, in \u001b[0;36mestimate_sparsity\u001b[1;34m(sorting, recording, num_spikes_for_sparsity, ms_before, ms_after, method, peak_sign, radius_um, num_channels, threshold, amplitude_mode, by_property, noise_levels, **job_kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m spikes \u001b[38;5;241m=\u001b[39m sorting\u001b[38;5;241m.\u001b[39mto_spike_vector()\n\u001b[0;32m    818\u001b[0m spikes \u001b[38;5;241m=\u001b[39m spikes[random_spikes_indices]\n\u001b[1;32m--> 820\u001b[0m templates_array \u001b[38;5;241m=\u001b[39m estimate_templates_with_accumulator(\n\u001b[0;32m    821\u001b[0m     recording,\n\u001b[0;32m    822\u001b[0m     spikes,\n\u001b[0;32m    823\u001b[0m     sorting\u001b[38;5;241m.\u001b[39munit_ids,\n\u001b[0;32m    824\u001b[0m     nbefore,\n\u001b[0;32m    825\u001b[0m     nafter,\n\u001b[0;32m    826\u001b[0m     return_scaled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    827\u001b[0m     job_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimate_sparsity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs,\n\u001b[0;32m    829\u001b[0m )\n\u001b[0;32m    830\u001b[0m templates \u001b[38;5;241m=\u001b[39m Templates(\n\u001b[0;32m    831\u001b[0m     templates_array\u001b[38;5;241m=\u001b[39mtemplates_array,\n\u001b[0;32m    832\u001b[0m     sampling_frequency\u001b[38;5;241m=\u001b[39mrecording\u001b[38;5;241m.\u001b[39msampling_frequency,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    837\u001b[0m     probe\u001b[38;5;241m=\u001b[39mprobe,\n\u001b[0;32m    838\u001b[0m )\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\core\\waveform_tools.py:866\u001b[0m, in \u001b[0;36mestimate_templates_with_accumulator\u001b[1;34m(recording, spikes, unit_ids, nbefore, nafter, return_scaled, job_name, return_std, verbose, **job_kwargs)\u001b[0m\n\u001b[0;32m    862\u001b[0m     job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimate_templates_with_accumulator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    863\u001b[0m processor \u001b[38;5;241m=\u001b[39m ChunkRecordingExecutor(\n\u001b[0;32m    864\u001b[0m     recording, func, init_func, init_args, job_name\u001b[38;5;241m=\u001b[39mjob_name, verbose\u001b[38;5;241m=\u001b[39mverbose, need_worker_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs\n\u001b[0;32m    865\u001b[0m )\n\u001b[1;32m--> 866\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# average\u001b[39;00m\n\u001b[0;32m    869\u001b[0m waveforms_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(waveform_accumulator_per_worker, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\core\\job_tools.py:482\u001b[0m, in \u001b[0;36mChunkRecordingExecutor.run\u001b[1;34m(self, recording_slices)\u001b[0m\n\u001b[0;32m    479\u001b[0m     worker_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m segment_index, frame_start, frame_stop \u001b[38;5;129;01min\u001b[39;00m recording_slices:\n\u001b[1;32m--> 482\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_returns:\n\u001b[0;32m    484\u001b[0m         returns\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\core\\waveform_tools.py:981\u001b[0m, in \u001b[0;36m_worker_estimate_templates\u001b[1;34m(segment_index, start_frame, end_frame, worker_dict)\u001b[0m\n\u001b[0;32m    978\u001b[0m end \u001b[38;5;241m=\u001b[39m spikes[l1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m nafter\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# load trace in memory\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m traces \u001b[38;5;241m=\u001b[39m \u001b[43mrecording\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_scaled\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m spike_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(l0, l1):\n\u001b[0;32m    986\u001b[0m     sample_index \u001b[38;5;241m=\u001b[39m spikes[spike_index][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_index\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\core\\baserecording.py:330\u001b[0m, in \u001b[0;36mBaseRecording.get_traces\u001b[1;34m(self, segment_index, start_frame, end_frame, channel_ids, order, return_scaled, cast_unsigned)\u001b[0m\n\u001b[0;32m    328\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mget_num_samples()\n\u001b[0;32m    329\u001b[0m end_frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(end_frame, num_samples)) \u001b[38;5;28;01mif\u001b[39;00m end_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_samples\n\u001b[1;32m--> 330\u001b[0m traces \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m order \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:367\u001b[0m, in \u001b[0;36mNeoRecordingSegment.get_traces\u001b[1;34m(self, start_frame, end_frame, channel_indices)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_traces\u001b[39m(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    363\u001b[0m     start_frame: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    364\u001b[0m     end_frame: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    365\u001b[0m     channel_indices: Union[List, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 367\u001b[0m     raw_traces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneo_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_analogsignal_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseg_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msegment_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_frame\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannel_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannel_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverted_gain:\n\u001b[0;32m    376\u001b[0m         raw_traces \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mraw_traces\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\neo\\rawio\\baserawio.py:1006\u001b[0m, in \u001b[0;36mBaseRawIO.get_analogsignal_chunk\u001b[1;34m(self, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes, channel_names, channel_ids, prefer_slice)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39mdiff(channel_indexes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1004\u001b[0m         channel_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(channel_indexes[\u001b[38;5;241m0\u001b[39m], channel_indexes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1006\u001b[0m raw_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_analogsignal_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m raw_chunk\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\neo\\rawio\\maxwellrawio.py:242\u001b[0m, in \u001b[0;36mMaxwellRawIO._get_analogsignal_chunk\u001b[1;34m(self, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(_hdf_maxwell_error)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m (e)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\neo\\rawio\\maxwellrawio.py:235\u001b[0m, in \u001b[0;36mMaxwellRawIO._get_analogsignal_chunk\u001b[1;34m(self, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_analogsignal_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes):\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 235\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_analogsignal_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mblock_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_indexes\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\neo\\rawio\\baserawio.py:1654\u001b[0m, in \u001b[0;36mBaseRawWithBufferApiIO._get_analogsignal_chunk\u001b[1;34m(self, block_index, seg_index, i_start, i_stop, stream_index, channel_indexes)\u001b[0m\n\u001b[0;32m   1652\u001b[0m     raw_sigs \u001b[38;5;241m=\u001b[39m full_raw_sigs[i_start:i_stop, :]\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m time_axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1654\u001b[0m     raw_sigs \u001b[38;5;241m=\u001b[39m \u001b[43mfull_raw_sigs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould never happen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\elias\\anaconda3\\envs\\dpqc\\lib\\site-packages\\h5py\\_hl\\dataset.py:802\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, args, new_dtype)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 802\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    804\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "File \u001b[1;32mh5py\\\\_selector.pyx:376\u001b[0m, in \u001b[0;36mh5py._selector.Reader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't synchronously read data (can't open directory)"
     ]
    }
   ],
   "source": [
    "# Note, you can set the number of cores you use using e.g.\n",
    "# si.set_global_job_kwargs(n_jobs = 8)\n",
    "\n",
    "# Choose sorting to train the model on\n",
    "well_id = 'well001'\n",
    "path_to_sorting = Path(save_root) / well_id / 'sorter_output'\n",
    "sorting_train = si.read_kilosort(folder_path=path_to_sorting)\n",
    "\n",
    "h5 = h5py.File(path)\n",
    "rec_name = list(h5['wells'][well_id].keys())[0]\n",
    "rec_train = si.MaxwellRecordingExtractor(path, stream_id=well_id, rec_name=rec_name)\n",
    "\n",
    "analyzer = si.create_sorting_analyzer(sorting=sorting_train, recording=rec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6823f0d-2ec1-4855-9ece-b8070926ec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikeinterface.curation import train_model\n",
    "\n",
    "analyzer_list = [analyzer_1, analyzer_2]\n",
    "labels_list = [analyzer_1_labels, analyzer_2_labels]\n",
    "output_folder = \"/path/to/output_folder\"\n",
    "\n",
    "trainer = train_model(\n",
    "    mode=\"analyzers\",\n",
    "    labels=labels_list,\n",
    "    analyzers=analyzer_list,\n",
    "    output_folder=output_folder,\n",
    "    metric_names=None, # Set if you want to use a subset of metrics, defaults to all calculated quality and template metrics\n",
    "    imputation_strategies=None, # Default is all available imputation strategies\n",
    "    scaling_techniques=None, # Default is all available scaling techniques\n",
    "    classifiers=None, # Defaults to Random Forest classifier only - we usually find this gives the best results, but a range of classifiers is available\n",
    "    seed=None, # Set a seed for reproducibility\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpqc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
